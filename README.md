# kr-mini-llm

MacBook Pro 16" M4 Maxì—ì„œ **ë‚˜ë§Œì˜ ì¤‘í˜• í•œêµ­ì–´ LLM**ì„ ê°œë°œí•˜ê¸° ìœ„í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.
ì´ ë ˆí¬ëŠ” `docs/`ì˜ ë¡œë“œë§µ/ê°€ì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ, **ì´ˆê¸° êµ¬ì¶•(Phase 1) ìŠ¤ìºí´ë”©**ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ–¥ï¸ í•˜ë“œì›¨ì–´ ìŠ¤í™
- **Chip**: Apple M4 Max
- **CPU**: 14-core (10 Performance + 4 Efficiency)
- **GPU**: 32-core
- **í†µí•© ë©”ëª¨ë¦¬**: 36GB

## ğŸ¯ ëª©í‘œ ëª¨ë¸
- **Medium**: 350M íŒŒë¼ë¯¸í„° (ê¶Œì¥)
- **Large**: 800M íŒŒë¼ë¯¸í„° (ë„ì „)
- **ì•„í‚¤í…ì²˜**: Transformer with RoPE, SwiGLU, RMSNorm, GQA
- **ì˜ˆìƒ í•™ìŠµ ì‹œê°„**: 22-44ì‹œê°„

## Quick Start (ê°€ì¥ ê°„ë‹¨í•œ ì´ˆê¸° êµ¬ì¶•)

ì•„ë˜ ì»¤ë§¨ë“œëŠ” **ë ˆí¬ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ** ì‹¤í–‰í•˜ì„¸ìš”.

```bash
# 1) ê°€ìƒí™˜ê²½
python3 -m venv venv
source venv/bin/activate
pip install -U pip

# 2) ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

## What you get
- **êµ¬ì¡°**: `src/`, `scripts/`, `configs/`, `tests/`, `docs/` ê¸°ë°˜ í”„ë¡œì íŠ¸ ë ˆì´ì•„ì›ƒ
- **M4 Max ìµœì í™”**: 36GB ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ì¤‘í˜• ëª¨ë¸ ì„¤ì •
- **ìƒì„¸ ë¬¸ì„œ**: [`M4_MAX_optimization_plan.md`](docs/M4_MAX_optimization_plan.md) ì°¸ê³ 
- **ë‹¤ìŒ ë‹¨ê³„ ì—°ê²°**: Phase 2+ (Tokenizer, ëª¨ë¸ ì•„í‚¤í…ì²˜, ë°ì´í„° íŒŒì´í”„ë¼ì¸, í•™ìŠµ/ì¶”ë¡ )ë¡œ í™•ì¥í•˜ê¸° ì‰¬ìš´ í‹€

## Project Structure (í•µì‹¬)
```
.
â”œâ”€â”€ configs/                  # ì„¤ì • íŒŒì¼
â”œâ”€â”€ docs/                     # ê°€ì´ë“œ/ë¡œë“œë§µ
â”œâ”€â”€ scripts/                  # ë°ì´í„° ì¤€ë¹„/í•™ìŠµ/ì¶”ë¡  ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â””â”€â”€ src/
    â”œâ”€â”€ data/                 # Tokenizer / Dataset
    â””â”€â”€ model/                # Transformer ëª¨ë¸ ì»´í¬ë„ŒíŠ¸
```

## ğŸ“š ë¬¸ì„œ

### ğŸš€ ì‹œì‘í•˜ê¸°
- **[Quick_start_guide.md](docs/Quick_start_guide.md)** â­ ë¨¼ì € ì½ê¸° - 5ë¶„ ì•ˆì— ì‹œì‘
- **[Setup_and_testing.md](docs/Setup_and_testing.md)** - ìƒì„¸ ì„¤ì • ë° í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

### ğŸ“‹ ê³„íš ë° ìµœì í™”
- **[M4_MAX_optimization_plan.md](docs/M4_MAX_optimization_plan.md)** â­ ìƒì„¸ ìµœì í™” ê°€ì´ë“œ
- **[Korean_llm_project_roadmap.md](docs/Korean_llm_project_roadmap.md)** - ì „ì²´ ë¡œë“œë§µ (6 Phases)
- **[Configuration_update_plan.md](docs/Configuration_update_plan.md)** - ì„¤ì • ì—…ë°ì´íŠ¸ ê³„íš

### ğŸ“– ë¬¸ì„œ ê°€ì´ë“œ
- **[docs/README.md](docs/README.md)** - ë¬¸ì„œ êµ¬ì¡° ë° ì½ê¸° ìˆœì„œ ê°€ì´ë“œ

## ğŸ¯ Next Steps

### ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
```bash
# 1. í™˜ê²½ ì„¤ì • í™•ì¸
source venv/bin/activate
python3 scripts/test_config.py

# 2. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ í…ŒìŠ¤íŠ¸
python3 scripts/train.py \
  --config configs/training_m4max.yaml \
  --model_config configs/model_medium.yaml
```

### Phase 2ë¶€í„° ì‹œì‘
1. **ëª¨ë¸ ì•„í‚¤í…ì²˜ êµ¬í˜„** (3-5ì¼)
   - RoPE, RMSNorm, GQA, SwiGLU
   - [Quick_start_guide.md > Phase 2](docs/Quick_start_guide.md#phase-2-ì•„í‚¤í…ì²˜-êµ¬í˜„-ğŸ—ï¸-3-5ì¼)

2. **ë°ì´í„° ì¤€ë¹„** (2-3ì¼)
   - 20-50GB í•œêµ­ì–´ ë°ì´í„° ìˆ˜ì§‘
   - Tokenizer í•™ìŠµ (32k vocab)

3. **í•™ìŠµ ì‹œì‘** (2-3ì£¼)
   - Medium ëª¨ë¸: 200k steps (~22ì‹œê°„)
   - [M4_MAX_optimization_plan.md](docs/M4_MAX_optimization_plan.md) ì°¸ê³ 

## ğŸš€ Quick Commands
```bash
# í™˜ê²½ ì„¤ì •
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# ë°ì´í„° ì¤€ë¹„ (Phase 3)
python scripts/prepare_data.py

# Tokenizer í•™ìŠµ (Phase 3)
python scripts/train_tokenizer.py --vocab_size 32000

# ëª¨ë¸ í•™ìŠµ (Phase 4)
python scripts/train.py --config configs/training_m4max.yaml

# í…ìŠ¤íŠ¸ ìƒì„± (Phase 5)
python scripts/generate.py --prompt "ì•ˆë…•í•˜ì„¸ìš”"
```
